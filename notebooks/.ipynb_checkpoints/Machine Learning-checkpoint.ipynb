{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What will happen to a dog in the shelter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, MinMaxScaler, MaxAbsScaler, RobustScaler\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import precision_score, accuracy_score, f1_score, recall_score\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_df = pd.read_csv(\"../data/unique_austin_shelter.csv\")\n",
    "unique_df.set_index(\"animal_id\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['is_mixed','intake_condition', 'intake_type', 'sex', 'fixed', 'time_in_shelter', 'age_in']\n",
    "features1 = ['intake_condition', 'intake_type', 'sex', 'fixed', 'time_in_shelter', 'age_in']\n",
    "features2 = ['is_mixed', 'sex', 'fixed', 'time_in_shelter', 'age_in']\n",
    "features3 = ['intake_condition', 'sex', 'time_in_shelter', 'age_in']\n",
    "features4 = ['is_mixed', 'intake_type', 'sex', 'fixed', 'age_in']\n",
    "features5 = ['is_mixed', 'sex', 'fixed', 'age_in']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_unique_df = unique_df[unique_df.in_shelter == \"No\"][['is_mixed', 'intake_condition', 'intake_type', 'name', 'sex', 'fixed', 'time_in_shelter', 'has_name', 'age_in','outcome_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = new_unique_df.time_in_shelter.apply(pd.to_timedelta)\n",
    "temp = temp.apply(lambda x:( x.days*24*60*60 + x.seconds)/60)\n",
    "new_unique_df.time_in_shelter = temp\n",
    "new_unique_df.time_in_shelter.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_unique_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_mixed</th>\n",
       "      <th>intake_condition</th>\n",
       "      <th>intake_type</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>fixed</th>\n",
       "      <th>time_in_shelter</th>\n",
       "      <th>has_name</th>\n",
       "      <th>age_in</th>\n",
       "      <th>outcome_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>animal_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A786884</th>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Stray</td>\n",
       "      <td>Brock</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>7132.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>Transfer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A706918</th>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Stray</td>\n",
       "      <td>Belle</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>134.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.005479</td>\n",
       "      <td>Return to Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A724273</th>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Stray</td>\n",
       "      <td>Runster</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>9994.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994521</td>\n",
       "      <td>Return to Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A778404</th>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Owner Surrender</td>\n",
       "      <td>Max</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>4784.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.002740</td>\n",
       "      <td>Adoption</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A682524</th>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Stray</td>\n",
       "      <td>Rio</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4538.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.002740</td>\n",
       "      <td>Return to Owner</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           is_mixed intake_condition      intake_type     name     sex fixed  \\\n",
       "animal_id                                                                      \n",
       "A786884           1           Normal            Stray    Brock    Male   Yes   \n",
       "A706918           0           Normal            Stray    Belle  Female   Yes   \n",
       "A724273           1           Normal            Stray  Runster    Male    No   \n",
       "A778404           1           Normal  Owner Surrender      Max    Male    No   \n",
       "A682524           1           Normal            Stray      Rio    Male   Yes   \n",
       "\n",
       "           time_in_shelter  has_name    age_in     outcome_type  \n",
       "animal_id                                                        \n",
       "A786884             7132.0         1  2.000000         Transfer  \n",
       "A706918              134.0         1  8.005479  Return to Owner  \n",
       "A724273             9994.0         1  0.994521  Return to Owner  \n",
       "A778404             4784.0         1  4.002740         Adoption  \n",
       "A682524             4538.0         1  4.002740  Return to Owner  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_unique_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Training Data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x_train_dict = new_unique_df[features].to_dict(orient=\"records\")\n",
    "y_train = new_unique_df['outcome_type']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vec = DictVectorizer(sparse=False)\n",
    "vec.fit(x_train_dict)\n",
    "x_train = vec.transform(x_train_dict)\n",
    "\n",
    "scaler = Normalizer()\n",
    "scaler.fit(x_train)\n",
    "x_train_sc = scaler.transform(x_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = KNeighborsClassifier(n_neighbors=9)\n",
    "vec = DictVectorizer(sparse=False)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"vectorizer\", vec), \n",
    "    (\"scaler\", scaler), \n",
    "    (\"model\", model)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: KNeighborsClassifier \n",
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['is_mixed', 'intake_condition', 'intake_type', 'sex', 'fixed', 'time_in_shelter', 'age_in'] 0.7032228834323774\n",
      "['intake_condition', 'intake_type', 'sex', 'fixed', 'time_in_shelter', 'age_in'] 0.7077282319862647\n",
      "['is_mixed', 'sex', 'fixed', 'time_in_shelter', 'age_in'] 0.6436777812883262\n",
      "['intake_condition', 'sex', 'time_in_shelter', 'age_in'] 0.6489118793058553\n",
      "['is_mixed', 'intake_type', 'sex', 'fixed', 'age_in'] 0.5778185926872705\n",
      "['is_mixed', 'sex', 'fixed', 'age_in'] 0.5211608681390264\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=30, n_jobs=-1)\n",
    "vec = DictVectorizer(sparse=False)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"vectorizer\", vec), \n",
    "    (\"scaler\", scaler), \n",
    "    (\"model\", model)\n",
    "])\n",
    "\n",
    "\n",
    "for feat in [features, features1, features2, features3, features4, features5]:\n",
    "    x_train_dict = new_unique_df[feat].to_dict(orient=\"records\")\n",
    "    y_train = new_unique_df['outcome_type']\n",
    "    print(feat, cross_val_score(pipeline, x_train_dict, y_train, cv=5, scoring=\"accuracy\").mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaler testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_dict = new_unique_df[features1].to_dict(orient=\"records\")\n",
    "y_train = new_unique_df['outcome_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = [StandardScaler(), Normalizer(), MinMaxScaler(), MaxAbsScaler(), RobustScaler()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  25 | elapsed:  1.0min remaining:   34.2s\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  25 | elapsed:  1.1min remaining:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vectorizer', DictVectorizer(dtype=<class 'numpy.float64'>, separator='=', sort=True,\n",
       "        sparse=False)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('model', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=-1, n_neighbors=30, p=2,\n",
       "           weights='uniform'))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'scaler': [StandardScaler(copy=True, with_mean=True, with_std=True), Normalizer(copy=True, norm='l2'), MinMaxScaler(copy=True, feature_range=(0, 1)), MaxAbsScaler(copy=True), RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
       "       with_scaling=True)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_kn = GridSearchCV(pipeline,param_grid=dict(scaler=scalers),cv=5, verbose=5, n_jobs=-1)\n",
    "grid_kn.fit(x_train_dict, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7174671657889727\n",
      "[('vectorizer', DictVectorizer(dtype=<class 'numpy.float64'>, separator='=', sort=True,\n",
      "        sparse=False)), ('scaler', RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "       with_scaling=True)), ('model', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=-1, n_neighbors=30, p=2,\n",
      "           weights='uniform'))]\n"
     ]
    }
   ],
   "source": [
    "print(grid_kn.best_score_)\n",
    "print(grid_kn.best_estimator_.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_scaler</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.389178</td>\n",
       "      <td>1.737522</td>\n",
       "      <td>5.464291</td>\n",
       "      <td>2.580006</td>\n",
       "      <td>StandardScaler(copy=True, with_mean=True, with...</td>\n",
       "      <td>{'scaler': StandardScaler(copy=True, with_mean...</td>\n",
       "      <td>0.704502</td>\n",
       "      <td>0.709324</td>\n",
       "      <td>0.709549</td>\n",
       "      <td>0.705014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.707728</td>\n",
       "      <td>0.002450</td>\n",
       "      <td>3</td>\n",
       "      <td>0.722456</td>\n",
       "      <td>0.721685</td>\n",
       "      <td>0.720041</td>\n",
       "      <td>0.721372</td>\n",
       "      <td>0.720817</td>\n",
       "      <td>0.721274</td>\n",
       "      <td>0.000813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.797246</td>\n",
       "      <td>0.486609</td>\n",
       "      <td>3.444275</td>\n",
       "      <td>0.803026</td>\n",
       "      <td>Normalizer(copy=True, norm='l2')</td>\n",
       "      <td>{'scaler': Normalizer(copy=True, norm='l2')}</td>\n",
       "      <td>0.708941</td>\n",
       "      <td>0.712020</td>\n",
       "      <td>0.713198</td>\n",
       "      <td>0.710885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.712709</td>\n",
       "      <td>0.003218</td>\n",
       "      <td>2</td>\n",
       "      <td>0.725787</td>\n",
       "      <td>0.724619</td>\n",
       "      <td>0.723293</td>\n",
       "      <td>0.723037</td>\n",
       "      <td>0.722799</td>\n",
       "      <td>0.723907</td>\n",
       "      <td>0.001132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.326220</td>\n",
       "      <td>1.045597</td>\n",
       "      <td>4.645742</td>\n",
       "      <td>0.474498</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>{'scaler': MinMaxScaler(copy=True, feature_ran...</td>\n",
       "      <td>0.697368</td>\n",
       "      <td>0.698065</td>\n",
       "      <td>0.700825</td>\n",
       "      <td>0.694224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697957</td>\n",
       "      <td>0.002205</td>\n",
       "      <td>4</td>\n",
       "      <td>0.713849</td>\n",
       "      <td>0.712881</td>\n",
       "      <td>0.712864</td>\n",
       "      <td>0.712094</td>\n",
       "      <td>0.710349</td>\n",
       "      <td>0.712407</td>\n",
       "      <td>0.001170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.784162</td>\n",
       "      <td>0.199169</td>\n",
       "      <td>4.616533</td>\n",
       "      <td>0.410775</td>\n",
       "      <td>MaxAbsScaler(copy=True)</td>\n",
       "      <td>{'scaler': MaxAbsScaler(copy=True)}</td>\n",
       "      <td>0.697210</td>\n",
       "      <td>0.698065</td>\n",
       "      <td>0.700666</td>\n",
       "      <td>0.694065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697798</td>\n",
       "      <td>0.002190</td>\n",
       "      <td>5</td>\n",
       "      <td>0.713929</td>\n",
       "      <td>0.712881</td>\n",
       "      <td>0.712785</td>\n",
       "      <td>0.712133</td>\n",
       "      <td>0.710349</td>\n",
       "      <td>0.712415</td>\n",
       "      <td>0.001183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.382561</td>\n",
       "      <td>0.384427</td>\n",
       "      <td>3.031501</td>\n",
       "      <td>1.061002</td>\n",
       "      <td>RobustScaler(copy=True, quantile_range=(25.0, ...</td>\n",
       "      <td>{'scaler': RobustScaler(copy=True, quantile_ra...</td>\n",
       "      <td>0.710368</td>\n",
       "      <td>0.715509</td>\n",
       "      <td>0.720654</td>\n",
       "      <td>0.717867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.717467</td>\n",
       "      <td>0.004349</td>\n",
       "      <td>1</td>\n",
       "      <td>0.729277</td>\n",
       "      <td>0.728109</td>\n",
       "      <td>0.728646</td>\n",
       "      <td>0.728588</td>\n",
       "      <td>0.729461</td>\n",
       "      <td>0.728816</td>\n",
       "      <td>0.000492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       3.389178      1.737522         5.464291        2.580006   \n",
       "1       1.797246      0.486609         3.444275        0.803026   \n",
       "2       4.326220      1.045597         4.645742        0.474498   \n",
       "3       4.784162      0.199169         4.616533        0.410775   \n",
       "4       2.382561      0.384427         3.031501        1.061002   \n",
       "\n",
       "                                        param_scaler  \\\n",
       "0  StandardScaler(copy=True, with_mean=True, with...   \n",
       "1                   Normalizer(copy=True, norm='l2')   \n",
       "2      MinMaxScaler(copy=True, feature_range=(0, 1))   \n",
       "3                            MaxAbsScaler(copy=True)   \n",
       "4  RobustScaler(copy=True, quantile_range=(25.0, ...   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'scaler': StandardScaler(copy=True, with_mean...           0.704502   \n",
       "1       {'scaler': Normalizer(copy=True, norm='l2')}           0.708941   \n",
       "2  {'scaler': MinMaxScaler(copy=True, feature_ran...           0.697368   \n",
       "3                {'scaler': MaxAbsScaler(copy=True)}           0.697210   \n",
       "4  {'scaler': RobustScaler(copy=True, quantile_ra...           0.710368   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score       ...         \\\n",
       "0           0.709324           0.709549           0.705014       ...          \n",
       "1           0.712020           0.713198           0.710885       ...          \n",
       "2           0.698065           0.700825           0.694224       ...          \n",
       "3           0.698065           0.700666           0.694065       ...          \n",
       "4           0.715509           0.720654           0.717867       ...          \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0         0.707728        0.002450                3            0.722456   \n",
       "1         0.712709        0.003218                2            0.725787   \n",
       "2         0.697957        0.002205                4            0.713849   \n",
       "3         0.697798        0.002190                5            0.713929   \n",
       "4         0.717467        0.004349                1            0.729277   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0            0.721685            0.720041            0.721372   \n",
       "1            0.724619            0.723293            0.723037   \n",
       "2            0.712881            0.712864            0.712094   \n",
       "3            0.712881            0.712785            0.712133   \n",
       "4            0.728109            0.728646            0.728588   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.720817          0.721274         0.000813  \n",
       "1            0.722799          0.723907         0.001132  \n",
       "2            0.710349          0.712407         0.001170  \n",
       "3            0.710349          0.712415         0.001183  \n",
       "4            0.729461          0.728816         0.000492  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_kn.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Robust scaler is the best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K value testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_dict = new_unique_df[features1].to_dict(orient=\"records\")\n",
    "y_train = new_unique_df['outcome_type']\n",
    "\n",
    "vec = DictVectorizer(sparse=False)\n",
    "vec.fit(x_train_dict)\n",
    "x_train = vec.transform(x_train_dict)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_sc = scaler.transform(x_train)\n",
    "\n",
    "model = KNeighborsClassifier(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = [5,10,20,30,40,50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [5, 10, 20, 30, 40, 50]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_kn_k = GridSearchCV(model,param_grid=dict(n_neighbors=ks),cv=5)\n",
    "grid_kn_k.fit(x_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7177526806674703\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "print(grid_kn_k.best_score_)\n",
    "print(grid_kn_k.best_estimator_.n_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22cdca45438>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(grid_kn_k.cv_results_).set_index(\"param_n_neighbors\")['mean_test_score'].plot.line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy = 0.7177526806674703\n",
    "\n",
    "k = 40\n",
    "\n",
    "scaler = RobustScaler()\n",
    "\n",
    "features = features1\n",
    "\n",
    "model = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
    "           weights='uniform'),\n",
    "       fit_params=None, iid='warn', n_jobs=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['is_mixed', 'intake_condition', 'intake_type', 'sex', 'fixed', 'time_in_shelter', 'age_in'] 0.682318257684175\n",
      "['intake_condition', 'intake_type', 'sex', 'fixed', 'time_in_shelter', 'age_in'] 0.6818729581376433\n",
      "['is_mixed', 'sex', 'fixed', 'time_in_shelter', 'age_in'] 0.607164489003684\n",
      "['intake_condition', 'sex', 'time_in_shelter', 'age_in'] 0.6085908160918031\n",
      "['is_mixed', 'intake_type', 'sex', 'fixed', 'age_in'] 0.5556448903594655\n",
      "['is_mixed', 'sex', 'fixed', 'age_in'] 0.5029837632974529\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_jobs=-1)\n",
    "vec = DictVectorizer(sparse=False)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"vectorizer\", vec), \n",
    "    (\"scaler\", scaler), \n",
    "    (\"model\", model)\n",
    "])\n",
    "\n",
    "\n",
    "for feat in [features, features1, features2, features3, features4, features5]:\n",
    "    x_train_dict = new_unique_df[feat].to_dict(orient=\"records\")\n",
    "    y_train = new_unique_df['outcome_type']\n",
    "    print(feat, cross_val_score(pipeline, x_train_dict, y_train, cv=5, scoring=\"accuracy\").mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaler Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_dict = new_unique_df[features].to_dict(orient=\"records\")\n",
    "y_train = new_unique_df['outcome_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = [StandardScaler(), Normalizer(), MinMaxScaler(), MaxAbsScaler(), RobustScaler()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  25 | elapsed:    7.9s remaining:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  25 | elapsed:    8.3s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    9.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vectorizer', DictVectorizer(dtype=<class 'numpy.float64'>, separator='=', sort=True,\n",
       "        sparse=False)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('model', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None..._jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'scaler': [StandardScaler(copy=True, with_mean=True, with_std=True), Normalizer(copy=True, norm='l2'), MinMaxScaler(copy=True, feature_range=(0, 1)), MaxAbsScaler(copy=True), RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
       "       with_scaling=True)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rf = GridSearchCV(pipeline,param_grid=dict(scaler=scalers),cv=5, verbose=5, n_jobs=-1)\n",
    "grid_rf.fit(x_train_dict, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6995749000697925\n",
      "[('vectorizer', DictVectorizer(dtype=<class 'numpy.float64'>, separator='=', sort=True,\n",
      "        sparse=False)), ('scaler', Normalizer(copy=True, norm='l2')), ('model', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False))]\n"
     ]
    }
   ],
   "source": [
    "print(grid_rf.best_score_)\n",
    "print(grid_rf.best_estimator_.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_scaler</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.388189</td>\n",
       "      <td>0.024891</td>\n",
       "      <td>0.150824</td>\n",
       "      <td>0.004430</td>\n",
       "      <td>StandardScaler(copy=True, with_mean=True, with...</td>\n",
       "      <td>{'scaler': StandardScaler(copy=True, with_mean...</td>\n",
       "      <td>0.681357</td>\n",
       "      <td>0.684586</td>\n",
       "      <td>0.691624</td>\n",
       "      <td>0.677245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.684855</td>\n",
       "      <td>0.005239</td>\n",
       "      <td>2</td>\n",
       "      <td>0.970691</td>\n",
       "      <td>0.969622</td>\n",
       "      <td>0.969942</td>\n",
       "      <td>0.969350</td>\n",
       "      <td>0.970896</td>\n",
       "      <td>0.970100</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.631151</td>\n",
       "      <td>0.142016</td>\n",
       "      <td>0.206917</td>\n",
       "      <td>0.055498</td>\n",
       "      <td>Normalizer(copy=True, norm='l2')</td>\n",
       "      <td>{'scaler': Normalizer(copy=True, norm='l2')}</td>\n",
       "      <td>0.701015</td>\n",
       "      <td>0.702188</td>\n",
       "      <td>0.700825</td>\n",
       "      <td>0.691526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.699575</td>\n",
       "      <td>0.004068</td>\n",
       "      <td>1</td>\n",
       "      <td>0.943841</td>\n",
       "      <td>0.942933</td>\n",
       "      <td>0.948450</td>\n",
       "      <td>0.947264</td>\n",
       "      <td>0.943497</td>\n",
       "      <td>0.945197</td>\n",
       "      <td>0.002223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.885217</td>\n",
       "      <td>0.068848</td>\n",
       "      <td>0.206124</td>\n",
       "      <td>0.016098</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>{'scaler': MinMaxScaler(copy=True, feature_ran...</td>\n",
       "      <td>0.676601</td>\n",
       "      <td>0.678877</td>\n",
       "      <td>0.691466</td>\n",
       "      <td>0.677721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.682571</td>\n",
       "      <td>0.006059</td>\n",
       "      <td>5</td>\n",
       "      <td>0.971960</td>\n",
       "      <td>0.970455</td>\n",
       "      <td>0.969387</td>\n",
       "      <td>0.969707</td>\n",
       "      <td>0.970143</td>\n",
       "      <td>0.970330</td>\n",
       "      <td>0.000893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.678293</td>\n",
       "      <td>0.033933</td>\n",
       "      <td>0.220505</td>\n",
       "      <td>0.048029</td>\n",
       "      <td>MaxAbsScaler(copy=True)</td>\n",
       "      <td>{'scaler': MaxAbsScaler(copy=True)}</td>\n",
       "      <td>0.678662</td>\n",
       "      <td>0.680304</td>\n",
       "      <td>0.686707</td>\n",
       "      <td>0.684545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.683491</td>\n",
       "      <td>0.003435</td>\n",
       "      <td>4</td>\n",
       "      <td>0.971682</td>\n",
       "      <td>0.971486</td>\n",
       "      <td>0.970616</td>\n",
       "      <td>0.970658</td>\n",
       "      <td>0.969151</td>\n",
       "      <td>0.970719</td>\n",
       "      <td>0.000893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.673698</td>\n",
       "      <td>0.133581</td>\n",
       "      <td>0.177439</td>\n",
       "      <td>0.033874</td>\n",
       "      <td>RobustScaler(copy=True, quantile_range=(25.0, ...</td>\n",
       "      <td>{'scaler': RobustScaler(copy=True, quantile_ra...</td>\n",
       "      <td>0.683893</td>\n",
       "      <td>0.681732</td>\n",
       "      <td>0.684010</td>\n",
       "      <td>0.683116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.684411</td>\n",
       "      <td>0.002578</td>\n",
       "      <td>3</td>\n",
       "      <td>0.971087</td>\n",
       "      <td>0.969662</td>\n",
       "      <td>0.970378</td>\n",
       "      <td>0.971134</td>\n",
       "      <td>0.970817</td>\n",
       "      <td>0.970616</td>\n",
       "      <td>0.000547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.388189      0.024891         0.150824        0.004430   \n",
       "1       0.631151      0.142016         0.206917        0.055498   \n",
       "2       0.885217      0.068848         0.206124        0.016098   \n",
       "3       0.678293      0.033933         0.220505        0.048029   \n",
       "4       0.673698      0.133581         0.177439        0.033874   \n",
       "\n",
       "                                        param_scaler  \\\n",
       "0  StandardScaler(copy=True, with_mean=True, with...   \n",
       "1                   Normalizer(copy=True, norm='l2')   \n",
       "2      MinMaxScaler(copy=True, feature_range=(0, 1))   \n",
       "3                            MaxAbsScaler(copy=True)   \n",
       "4  RobustScaler(copy=True, quantile_range=(25.0, ...   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'scaler': StandardScaler(copy=True, with_mean...           0.681357   \n",
       "1       {'scaler': Normalizer(copy=True, norm='l2')}           0.701015   \n",
       "2  {'scaler': MinMaxScaler(copy=True, feature_ran...           0.676601   \n",
       "3                {'scaler': MaxAbsScaler(copy=True)}           0.678662   \n",
       "4  {'scaler': RobustScaler(copy=True, quantile_ra...           0.683893   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score       ...         \\\n",
       "0           0.684586           0.691624           0.677245       ...          \n",
       "1           0.702188           0.700825           0.691526       ...          \n",
       "2           0.678877           0.691466           0.677721       ...          \n",
       "3           0.680304           0.686707           0.684545       ...          \n",
       "4           0.681732           0.684010           0.683116       ...          \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0         0.684855        0.005239                2            0.970691   \n",
       "1         0.699575        0.004068                1            0.943841   \n",
       "2         0.682571        0.006059                5            0.971960   \n",
       "3         0.683491        0.003435                4            0.971682   \n",
       "4         0.684411        0.002578                3            0.971087   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0            0.969622            0.969942            0.969350   \n",
       "1            0.942933            0.948450            0.947264   \n",
       "2            0.970455            0.969387            0.969707   \n",
       "3            0.971486            0.970616            0.970658   \n",
       "4            0.969662            0.970378            0.971134   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.970896          0.970100         0.000600  \n",
       "1            0.943497          0.945197         0.002223  \n",
       "2            0.970143          0.970330         0.000893  \n",
       "3            0.969151          0.970719         0.000893  \n",
       "4            0.970817          0.970616         0.000547  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_rf.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_dict = new_unique_df[features].to_dict(orient=\"records\")\n",
    "y_train = new_unique_df['outcome_type']\n",
    "\n",
    "vec = DictVectorizer(sparse=False)\n",
    "vec.fit(x_train_dict)\n",
    "x_train = vec.transform(x_train_dict)\n",
    "\n",
    "scaler = Normalizer()\n",
    "scaler.fit(x_train)\n",
    "x_train_sc = scaler.transform(x_train)\n",
    "\n",
    "model = RandomForestClassifier(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [10, 50, 90, 100],\n",
    "    'max_features': [2, 3],\n",
    "    'random_state': [10],\n",
    "    'min_samples_leaf': [2, 3, 4],\n",
    "    'min_samples_split': [10, 12, 15],\n",
    "    'n_estimators': [300, 1000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed: 22.1min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed: 42.3min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed: 49.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'bootstrap': [True], 'max_depth': [10, 50, 90, 100], 'max_features': [2, 3], 'random_state': [10], 'min_samples_leaf': [2, 3, 4], 'min_samples_split': [10, 12, 15], 'n_estimators': [300, 1000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rf_p = GridSearchCV(model,param_grid=param_grid,cv=5, n_jobs=-1, verbose=2)\n",
    "grid_rf_p.fit(x_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7355814986358734\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=50, max_features=3, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=3, min_samples_split=12,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,\n",
      "            oob_score=False, random_state=10, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(grid_rf_p.best_score_)\n",
    "print(grid_rf_p.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy = 0.7355814986358734\n",
    "\n",
    "scaler = Normalizer()\n",
    "\n",
    "features = features\n",
    "\n",
    "model = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=90, max_features=2, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=2, min_samples_split=15,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,\n",
    "            oob_score=False, random_state=10, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]['is_mixed', 'intake_condition', 'intake_type', 'sex', 'fixed', 'time_in_shelter', 'age_in'] 0.6486269295505558\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]['intake_condition', 'intake_type', 'sex', 'fixed', 'time_in_shelter', 'age_in'] 0.6475794719825141\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]['is_mixed', 'sex', 'fixed', 'time_in_shelter', 'age_in'] 0.5903501885342708\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]['intake_condition', 'sex', 'time_in_shelter', 'age_in'] 0.6080208264816255\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]['is_mixed', 'intake_type', 'sex', 'fixed', 'age_in'] 0.5793102526146894\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]['is_mixed', 'sex', 'fixed', 'age_in'] 0.5220492634024069\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC(verbose=2)\n",
    "vec = DictVectorizer(sparse=False)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"vectorizer\", vec), \n",
    "    (\"scaler\", scaler), \n",
    "    (\"model\", model)\n",
    "])\n",
    "\n",
    "\n",
    "for feat in [features, features1, features2, features3, features4, features5]:\n",
    "    x_train_dict = new_unique_df[feat].to_dict(orient=\"records\")\n",
    "    y_train = new_unique_df['outcome_type']\n",
    "    print(feat, cross_val_score(pipeline, x_train_dict, y_train, cv=5, scoring=\"accuracy\").mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaler Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_dict = new_unique_df[features].to_dict(orient=\"records\")\n",
    "y_train = new_unique_df['outcome_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = [StandardScaler(), Normalizer(), MinMaxScaler(), MaxAbsScaler(), RobustScaler()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  25 | elapsed:  1.1min remaining:   38.5s\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  25 | elapsed:  1.3min remaining:   10.4s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vectorizer', DictVectorizer(dtype=<class 'numpy.float64'>, separator='=', sort=True,\n",
       "        sparse=False)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('model', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=2))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'scaler': [StandardScaler(copy=True, with_mean=True, with_std=True), Normalizer(copy=True, norm='l2'), MinMaxScaler(copy=True, feature_range=(0, 1)), MaxAbsScaler(copy=True), RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
       "       with_scaling=True)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=5)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_ls = GridSearchCV(pipeline,param_grid=dict(scaler=scalers),cv=5, verbose=5, n_jobs=-1)\n",
    "grid_ls.fit(x_train_dict, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6539876911363492\n",
      "[('vectorizer', DictVectorizer(dtype=<class 'numpy.float64'>, separator='=', sort=True,\n",
      "        sparse=False)), ('scaler', RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "       with_scaling=True)), ('model', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=2))]\n"
     ]
    }
   ],
   "source": [
    "print(grid_ls.best_score_)\n",
    "print(grid_ls.best_estimator_.steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_dict = new_unique_df[features].to_dict(orient=\"records\")\n",
    "y_train = new_unique_df['outcome_type']\n",
    "\n",
    "vec = DictVectorizer(sparse=False)\n",
    "vec.fit(x_train_dict)\n",
    "x_train = vec.transform(x_train_dict)\n",
    "\n",
    "scaler = Normalizer()\n",
    "scaler.fit(x_train)\n",
    "x_train_sc = scaler.transform(x_train)\n",
    "\n",
    "model = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "    'max_iter': [500,1000,1500]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done  75 out of  75 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10], 'max_iter': [500, 1000, 1500]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_ls_p = GridSearchCV(model,param_grid=param_grid,cv=5, n_jobs=-1, verbose=2)\n",
    "grid_ls_p.fit(x_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5426686123976905\n",
      "LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=500,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n"
     ]
    }
   ],
   "source": [
    "print(grid_ls_p.best_score_)\n",
    "print(grid_ls_p.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy = 0.5426686123976905\n",
    "\n",
    "scaler = RobustScaler()\n",
    "\n",
    "features = features\n",
    "\n",
    "model = LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
    "     intercept_scaling=1, loss='squared_hinge', max_iter=500,\n",
    "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
    "     verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['is_mixed', 'intake_condition', 'intake_type', 'sex', 'fixed', 'time_in_shelter', 'age_in'] 0.6966564793830872\n",
      "['intake_condition', 'intake_type', 'sex', 'fixed', 'time_in_shelter', 'age_in'] 0.7007167493294919\n",
      "['is_mixed', 'sex', 'fixed', 'time_in_shelter', 'age_in'] 0.6202020697585997\n",
      "['intake_condition', 'sex', 'time_in_shelter', 'age_in'] 0.6205505114944501\n",
      "['is_mixed', 'intake_type', 'sex', 'fixed', 'age_in'] 0.5584047106254516\n",
      "['is_mixed', 'sex', 'fixed', 'age_in'] 0.5052356678565763\n"
     ]
    }
   ],
   "source": [
    "model = BaggingClassifier(n_jobs=-1)\n",
    "vec = DictVectorizer(sparse=False)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"vectorizer\", vec), \n",
    "    (\"scaler\", scaler), \n",
    "    (\"model\", model)\n",
    "])\n",
    "\n",
    "\n",
    "for feat in [features, features1, features2, features3, features4, features5]:\n",
    "    x_train_dict = new_unique_df[feat].to_dict(orient=\"records\")\n",
    "    y_train = new_unique_df['outcome_type']\n",
    "    print(feat, cross_val_score(pipeline, x_train_dict, y_train, cv=5, scoring=\"accuracy\").mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaler Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_dict = new_unique_df[features1].to_dict(orient=\"records\")\n",
    "y_train = new_unique_df['outcome_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = [StandardScaler(), Normalizer(), MinMaxScaler(), MaxAbsScaler(), RobustScaler()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  25 | elapsed:   10.3s remaining:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  25 | elapsed:   12.5s remaining:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:   12.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vectorizer', DictVectorizer(dtype=<class 'numpy.float64'>, separator='=', sort=True,\n",
       "        sparse=False)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('model', BaggingClassifier(base_estimator=None, bootstrap=True,\n",
       "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
       "         n_estimators=10, n_jobs=-1, oob_score=False, random_state=None,\n",
       "         verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'scaler': [StandardScaler(copy=True, with_mean=True, with_std=True), Normalizer(copy=True, norm='l2'), MinMaxScaler(copy=True, feature_range=(0, 1)), MaxAbsScaler(copy=True), RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
       "       with_scaling=True)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=5)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_bc = GridSearchCV(pipeline,param_grid=dict(scaler=scalers),cv=5, verbose=5, n_jobs=-1)\n",
    "grid_bc.fit(x_train_dict, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7015100564684982\n",
      "[('vectorizer', DictVectorizer(dtype=<class 'numpy.float64'>, separator='=', sort=True,\n",
      "        sparse=False)), ('scaler', MaxAbsScaler(copy=True)), ('model', BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=10, n_jobs=-1, oob_score=False, random_state=None,\n",
      "         verbose=0, warm_start=False))]\n"
     ]
    }
   ],
   "source": [
    "print(grid_bc.best_score_)\n",
    "print(grid_bc.best_estimator_.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_scaler</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.198086</td>\n",
       "      <td>0.074320</td>\n",
       "      <td>0.081228</td>\n",
       "      <td>0.007823</td>\n",
       "      <td>StandardScaler(copy=True, with_mean=True, with...</td>\n",
       "      <td>{'scaler': StandardScaler(copy=True, with_mean...</td>\n",
       "      <td>0.697844</td>\n",
       "      <td>0.698224</td>\n",
       "      <td>0.701459</td>\n",
       "      <td>0.695176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697671</td>\n",
       "      <td>0.002235</td>\n",
       "      <td>4</td>\n",
       "      <td>0.975371</td>\n",
       "      <td>0.973350</td>\n",
       "      <td>0.976644</td>\n",
       "      <td>0.975852</td>\n",
       "      <td>0.975178</td>\n",
       "      <td>0.975279</td>\n",
       "      <td>0.001089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.070022</td>\n",
       "      <td>0.233845</td>\n",
       "      <td>0.139015</td>\n",
       "      <td>0.013698</td>\n",
       "      <td>Normalizer(copy=True, norm='l2')</td>\n",
       "      <td>{'scaler': Normalizer(copy=True, norm='l2')}</td>\n",
       "      <td>0.687223</td>\n",
       "      <td>0.699175</td>\n",
       "      <td>0.697494</td>\n",
       "      <td>0.683910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.692532</td>\n",
       "      <td>0.005945</td>\n",
       "      <td>5</td>\n",
       "      <td>0.957127</td>\n",
       "      <td>0.957368</td>\n",
       "      <td>0.957253</td>\n",
       "      <td>0.957375</td>\n",
       "      <td>0.957811</td>\n",
       "      <td>0.957387</td>\n",
       "      <td>0.000231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.704144</td>\n",
       "      <td>0.200334</td>\n",
       "      <td>0.123035</td>\n",
       "      <td>0.008896</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>{'scaler': MinMaxScaler(copy=True, feature_ran...</td>\n",
       "      <td>0.698003</td>\n",
       "      <td>0.701871</td>\n",
       "      <td>0.703680</td>\n",
       "      <td>0.691209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.699702</td>\n",
       "      <td>0.004730</td>\n",
       "      <td>3</td>\n",
       "      <td>0.974538</td>\n",
       "      <td>0.975452</td>\n",
       "      <td>0.974701</td>\n",
       "      <td>0.975575</td>\n",
       "      <td>0.975099</td>\n",
       "      <td>0.975073</td>\n",
       "      <td>0.000405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.900506</td>\n",
       "      <td>0.028042</td>\n",
       "      <td>0.147803</td>\n",
       "      <td>0.019733</td>\n",
       "      <td>MaxAbsScaler(copy=True)</td>\n",
       "      <td>{'scaler': MaxAbsScaler(copy=True)}</td>\n",
       "      <td>0.697527</td>\n",
       "      <td>0.699810</td>\n",
       "      <td>0.709708</td>\n",
       "      <td>0.697080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.701510</td>\n",
       "      <td>0.004675</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975648</td>\n",
       "      <td>0.973786</td>\n",
       "      <td>0.977357</td>\n",
       "      <td>0.975852</td>\n",
       "      <td>0.975496</td>\n",
       "      <td>0.975628</td>\n",
       "      <td>0.001136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.776486</td>\n",
       "      <td>0.072086</td>\n",
       "      <td>0.094775</td>\n",
       "      <td>0.009417</td>\n",
       "      <td>RobustScaler(copy=True, quantile_range=(25.0, ...</td>\n",
       "      <td>{'scaler': RobustScaler(copy=True, quantile_ra...</td>\n",
       "      <td>0.698478</td>\n",
       "      <td>0.699017</td>\n",
       "      <td>0.703046</td>\n",
       "      <td>0.698032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.700114</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>2</td>\n",
       "      <td>0.974260</td>\n",
       "      <td>0.975809</td>\n",
       "      <td>0.974780</td>\n",
       "      <td>0.974425</td>\n",
       "      <td>0.976289</td>\n",
       "      <td>0.975113</td>\n",
       "      <td>0.000797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       1.198086      0.074320         0.081228        0.007823   \n",
       "1       3.070022      0.233845         0.139015        0.013698   \n",
       "2       1.704144      0.200334         0.123035        0.008896   \n",
       "3       1.900506      0.028042         0.147803        0.019733   \n",
       "4       1.776486      0.072086         0.094775        0.009417   \n",
       "\n",
       "                                        param_scaler  \\\n",
       "0  StandardScaler(copy=True, with_mean=True, with...   \n",
       "1                   Normalizer(copy=True, norm='l2')   \n",
       "2      MinMaxScaler(copy=True, feature_range=(0, 1))   \n",
       "3                            MaxAbsScaler(copy=True)   \n",
       "4  RobustScaler(copy=True, quantile_range=(25.0, ...   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'scaler': StandardScaler(copy=True, with_mean...           0.697844   \n",
       "1       {'scaler': Normalizer(copy=True, norm='l2')}           0.687223   \n",
       "2  {'scaler': MinMaxScaler(copy=True, feature_ran...           0.698003   \n",
       "3                {'scaler': MaxAbsScaler(copy=True)}           0.697527   \n",
       "4  {'scaler': RobustScaler(copy=True, quantile_ra...           0.698478   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score       ...         \\\n",
       "0           0.698224           0.701459           0.695176       ...          \n",
       "1           0.699175           0.697494           0.683910       ...          \n",
       "2           0.701871           0.703680           0.691209       ...          \n",
       "3           0.699810           0.709708           0.697080       ...          \n",
       "4           0.699017           0.703046           0.698032       ...          \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0         0.697671        0.002235                4            0.975371   \n",
       "1         0.692532        0.005945                5            0.957127   \n",
       "2         0.699702        0.004730                3            0.974538   \n",
       "3         0.701510        0.004675                1            0.975648   \n",
       "4         0.700114        0.002018                2            0.974260   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0            0.973350            0.976644            0.975852   \n",
       "1            0.957368            0.957253            0.957375   \n",
       "2            0.975452            0.974701            0.975575   \n",
       "3            0.973786            0.977357            0.975852   \n",
       "4            0.975809            0.974780            0.974425   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.975178          0.975279         0.001089  \n",
       "1            0.957811          0.957387         0.000231  \n",
       "2            0.975099          0.975073         0.000405  \n",
       "3            0.975496          0.975628         0.001136  \n",
       "4            0.976289          0.975113         0.000797  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_bc.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_dict = new_unique_df[features1].to_dict(orient=\"records\")\n",
    "y_train = new_unique_df['outcome_type']\n",
    "\n",
    "vec = DictVectorizer(sparse=False)\n",
    "vec.fit(x_train_dict)\n",
    "x_train = vec.transform(x_train_dict)\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_sc = scaler.transform(x_train)\n",
    "\n",
    "model = BaggingClassifier(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_samples': [600,800,1000],\n",
    "    'max_features': [0.5, 0.75, 1],\n",
    "    'random_state': [10],\n",
    "    'n_estimators': [100, 200, 300, 500]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   40.5s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  3.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=BaggingClassifier(base_estimator=None, bootstrap=True,\n",
       "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
       "         n_estimators=10, n_jobs=-1, oob_score=False, random_state=None,\n",
       "         verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'max_samples': [600, 800, 1000], 'max_features': [0.5, 0.75, 1], 'random_state': [10], 'n_estimators': [100, 200, 300, 500]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_bc_p = GridSearchCV(model,param_grid=param_grid,cv=5, n_jobs=-1, verbose=2)\n",
    "grid_bc_p.fit(x_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7329801408540068\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=0.75, max_samples=1000,\n",
      "         n_estimators=500, n_jobs=-1, oob_score=False, random_state=10,\n",
      "         verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(grid_bc_p.best_score_)\n",
    "print(grid_bc_p.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy = 0.7347884017511579\n",
    "\n",
    "scaler = Normalizer()\n",
    "\n",
    "features = features\n",
    "\n",
    "model = BaggingClassifier(base_estimator=None, bootstrap=True,\n",
    "         bootstrap_features=False, max_features=0.75, max_samples=1000,\n",
    "         n_estimators=200, n_jobs=-1, oob_score=False, random_state=10,\n",
    "         verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting what will happen to a dog in the shelter\n",
    "* **Best Model: RandomForestClassifier**\n",
    "\n",
    "* 2nd Best Model: BaggingClassifier\n",
    "* 3rd Model: KNeighborsClassifier\n",
    "* Worst Model: LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=90, max_features=2, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=2, min_samples_split=15,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,\n",
       "            oob_score=False, random_state=10, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_dict = new_unique_df[features].to_dict(orient=\"records\")\n",
    "y_train = new_unique_df['outcome_type']\n",
    "\n",
    "vec = DictVectorizer(sparse=False)\n",
    "vec.fit(x_train_dict)\n",
    "x_train = vec.transform(x_train_dict)\n",
    "\n",
    "scaler = Normalizer()\n",
    "scaler.fit(x_train)\n",
    "x_train_sc = scaler.transform(x_train)\n",
    "\n",
    "model = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini', max_depth=90, \n",
    "                               max_features=2, max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "                               min_impurity_split=None, min_samples_leaf=2, min_samples_split=15, \n",
    "                               min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1, \n",
    "                               oob_score=False, random_state=10, verbose=0, warm_start=False)\n",
    "model.fit(x_train_sc, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating our best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = (model.predict(x_train_sc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7854831546221687"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transfer 0.7699004975124378\n",
      "Return to Owner 0.9263483265828182\n",
      "Adoption 0.716197409270956\n",
      "nan 0.0\n",
      "Died 0.0\n",
      "Euthanasia 0.8801652892561983\n",
      "Rto-Adopt 0.0\n",
      "Disposal 0.0\n",
      "Missing 0.0\n"
     ]
    }
   ],
   "source": [
    "for outcome_type in unique_df.outcome_type.unique():\n",
    "    print(outcome_type, precision_score(y_train==outcome_type, y_train_pred==outcome_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transfer 0.3750378673129355\n",
      "Return to Owner 0.8716277203891285\n",
      "Adoption 0.9650198341146773\n",
      "nan 0.0\n",
      "Died 0.0\n",
      "Euthanasia 0.25326991676575505\n",
      "Rto-Adopt 0.0\n",
      "Disposal 0.0\n",
      "Missing 0.0\n"
     ]
    }
   ],
   "source": [
    "for outcome_type in unique_df.outcome_type.unique():\n",
    "    print(outcome_type, recall_score(y_train==outcome_type, y_train_pred==outcome_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing our model on a dog in the shelter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate an undaopted dog's time in shelter\n",
    "def calc_time_in_shelter(date_in):\n",
    "    time_in_shelter = pd.to_datetime('today') - pd.to_datetime(date_in)\n",
    "    time_in_shelter = (time_in_shelter.days*24*60*60 + time_in_shelter.seconds)/60\n",
    "    return time_in_shelter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "unadopted_dogs = unique_df.loc[unique_df.in_shelter == \"Yes\"]\n",
    "unadopted_dogs.time_in_shelter = unadopted_dogs.date_in.apply(calc_time_in_shelter)\n",
    "\n",
    "unadopted_dogs = unadopted_dogs[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "unadopted_dogs_dict = unadopted_dogs.to_dict(orient=\"records\")\n",
    "unadopted_dogs = vec.transform(unadopted_dogs_dict)\n",
    "unadopted_dogs_sc = scaler.transform(unadopted_dogs)\n",
    "\n",
    "y_test_preds = model.predict(unadopted_dogs_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adoption           356\n",
       "Return to Owner     38\n",
       "Transfer            31\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_test_preds)[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adoption           0.837647\n",
       "Return to Owner    0.089412\n",
       "Transfer           0.072941\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pd.DataFrame(y_test_preds)[0].value_counts() / \n",
    " pd.DataFrame(y_test_preds)[0].value_counts().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adoption           0.453396\n",
       "Return to Owner    0.260584\n",
       "Transfer           0.243030\n",
       "Euthanasia         0.033974\n",
       "Died               0.004256\n",
       "Rto-Adopt          0.004155\n",
       "Disposal           0.000302\n",
       "Missing            0.000302\n",
       "Name: outcome_type, dtype: float64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(unique_df.loc[unique_df.in_shelter == \"No\"]['outcome_type'].value_counts() / \n",
    "unique_df.loc[unique_df.in_shelter == \"No\"]['outcome_type'].value_counts().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "**We predicted that 83% of the dogs currently in the shelter will be adopted. However, based on the dogs that are no longer in the shelter, only 45% were adopted. Also, our model never predicted that the dogs currently in the shelter will never be euthanized, die, be disposed of, or go missing.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Will your dog get adopted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_mixed</th>\n",
       "      <th>intake_condition</th>\n",
       "      <th>intake_type</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>fixed</th>\n",
       "      <th>time_in_shelter</th>\n",
       "      <th>has_name</th>\n",
       "      <th>age_in</th>\n",
       "      <th>outcome_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>animal_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A786884</th>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Stray</td>\n",
       "      <td>Brock</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>7132.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>Transfer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A706918</th>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Stray</td>\n",
       "      <td>Belle</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>134.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.005479</td>\n",
       "      <td>Return to Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A724273</th>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Stray</td>\n",
       "      <td>Runster</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>9994.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994521</td>\n",
       "      <td>Return to Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A778404</th>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Owner Surrender</td>\n",
       "      <td>Max</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>4784.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.002740</td>\n",
       "      <td>Adoption</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A682524</th>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Stray</td>\n",
       "      <td>Rio</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4538.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.002740</td>\n",
       "      <td>Return to Owner</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           is_mixed intake_condition      intake_type     name     sex fixed  \\\n",
       "animal_id                                                                      \n",
       "A786884           1           Normal            Stray    Brock    Male   Yes   \n",
       "A706918           0           Normal            Stray    Belle  Female   Yes   \n",
       "A724273           1           Normal            Stray  Runster    Male    No   \n",
       "A778404           1           Normal  Owner Surrender      Max    Male    No   \n",
       "A682524           1           Normal            Stray      Rio    Male   Yes   \n",
       "\n",
       "           time_in_shelter  has_name    age_in     outcome_type  \n",
       "animal_id                                                        \n",
       "A786884             7132.0         1  2.000000         Transfer  \n",
       "A706918              134.0         1  8.005479  Return to Owner  \n",
       "A724273             9994.0         1  0.994521  Return to Owner  \n",
       "A778404             4784.0         1  4.002740         Adoption  \n",
       "A682524             4538.0         1  4.002740  Return to Owner  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_unique_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_features1 = ['is_mixed','intake_condition', 'intake_type', 'sex', 'fixed', 'age_in', 'has_name']\n",
    "your_features2 = ['intake_condition', 'intake_type', 'sex', 'fixed', 'age_in', 'has_name']\n",
    "your_features3 = ['is_mixed', 'intake_type', 'sex', 'fixed', 'age_in', 'has_name']\n",
    "your_features4 = ['is_mixed', 'sex', 'fixed', 'age_in', 'has_name']\n",
    "your_features5 = ['intake_condition', 'sex', 'age_in', 'has_name']\n",
    "your_features6 = ['is_mixed', 'sex', 'fixed', 'age_in']\n",
    "your_features = [your_features1, your_features2, your_features3, your_features4, your_features5, your_features6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: KNeighborsClassifier \n",
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   17.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['is_mixed', 'intake_condition', 'intake_type', 'sex', 'fixed', 'age_in', 'has_name'] 0.5821020606653055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   16.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['intake_condition', 'intake_type', 'sex', 'fixed', 'age_in', 'has_name'] 0.5824201244870114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    6.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['is_mixed', 'intake_type', 'sex', 'fixed', 'age_in', 'has_name'] 0.5778185926872705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    3.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['is_mixed', 'sex', 'fixed', 'age_in', 'has_name'] 0.5211608681390264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   14.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['intake_condition', 'sex', 'age_in', 'has_name'] 0.50456923284251\n",
      "['is_mixed', 'sex', 'fixed', 'age_in'] 0.5211608681390264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.8s finished\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=30, n_jobs=-1)\n",
    "vec = DictVectorizer(sparse=False)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"vectorizer\", vec), \n",
    "    (\"scaler\", scaler), \n",
    "    (\"model\", model)\n",
    "])\n",
    "\n",
    "\n",
    "for feat in your_features:\n",
    "    x_train_dict = new_unique_df[feat].to_dict(orient=\"records\")\n",
    "    y_train = new_unique_df['outcome_type']\n",
    "    print(feat, cross_val_score(pipeline, x_train_dict, y_train, cv=5, scoring=\"accuracy\", verbose=1).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaler testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_dict = new_unique_df[your_features2].to_dict(orient=\"records\")\n",
    "y_train = new_unique_df['outcome_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = [StandardScaler(), Normalizer(), MinMaxScaler(), MaxAbsScaler(), RobustScaler()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   23.5s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  25 | elapsed:  1.1min remaining:   36.6s\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  25 | elapsed:  1.3min remaining:   10.7s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vectorizer', DictVectorizer(dtype=<class 'numpy.float64'>, separator='=', sort=True,\n",
       "        sparse=False)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('model', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=-1, n_neighbors=30, p=2,\n",
       "           weights='uniform'))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'scaler': [StandardScaler(copy=True, with_mean=True, with_std=True), Normalizer(copy=True, norm='l2'), MinMaxScaler(copy=True, feature_range=(0, 1)), MaxAbsScaler(copy=True), RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
       "       with_scaling=True)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=5)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_kn = GridSearchCV(pipeline,param_grid=dict(scaler=scalers),cv=5, verbose=5, n_jobs=-1)\n",
    "grid_kn.fit(x_train_dict, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5836241355243956\n",
      "[('vectorizer', DictVectorizer(dtype=<class 'numpy.float64'>, separator='=', sort=True,\n",
      "        sparse=False)), ('scaler', Normalizer(copy=True, norm='l2')), ('model', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=-1, n_neighbors=30, p=2,\n",
      "           weights='uniform'))]\n"
     ]
    }
   ],
   "source": [
    "print(grid_kn.best_score_)\n",
    "print(grid_kn.best_estimator_.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_scaler</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.325717</td>\n",
       "      <td>1.584996</td>\n",
       "      <td>5.858148</td>\n",
       "      <td>1.601921</td>\n",
       "      <td>StandardScaler(copy=True, with_mean=True, with...</td>\n",
       "      <td>{'scaler': StandardScaler(copy=True, with_mean...</td>\n",
       "      <td>0.571972</td>\n",
       "      <td>0.584681</td>\n",
       "      <td>0.585660</td>\n",
       "      <td>0.586322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.582419</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>2</td>\n",
       "      <td>0.593440</td>\n",
       "      <td>0.595733</td>\n",
       "      <td>0.593941</td>\n",
       "      <td>0.594409</td>\n",
       "      <td>0.595757</td>\n",
       "      <td>0.594656</td>\n",
       "      <td>0.000941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.307196</td>\n",
       "      <td>1.115818</td>\n",
       "      <td>3.752201</td>\n",
       "      <td>0.997321</td>\n",
       "      <td>Normalizer(copy=True, norm='l2')</td>\n",
       "      <td>{'scaler': Normalizer(copy=True, norm='l2')}</td>\n",
       "      <td>0.576094</td>\n",
       "      <td>0.583095</td>\n",
       "      <td>0.587722</td>\n",
       "      <td>0.588385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583624</td>\n",
       "      <td>0.004407</td>\n",
       "      <td>1</td>\n",
       "      <td>0.594670</td>\n",
       "      <td>0.596129</td>\n",
       "      <td>0.594734</td>\n",
       "      <td>0.592149</td>\n",
       "      <td>0.594568</td>\n",
       "      <td>0.594450</td>\n",
       "      <td>0.001285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.755791</td>\n",
       "      <td>1.219479</td>\n",
       "      <td>3.382347</td>\n",
       "      <td>1.178871</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>{'scaler': MinMaxScaler(copy=True, feature_ran...</td>\n",
       "      <td>0.579264</td>\n",
       "      <td>0.564859</td>\n",
       "      <td>0.583439</td>\n",
       "      <td>0.587591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.579754</td>\n",
       "      <td>0.007901</td>\n",
       "      <td>3</td>\n",
       "      <td>0.597010</td>\n",
       "      <td>0.579434</td>\n",
       "      <td>0.591244</td>\n",
       "      <td>0.594251</td>\n",
       "      <td>0.597145</td>\n",
       "      <td>0.591817</td>\n",
       "      <td>0.006557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.119946</td>\n",
       "      <td>1.098841</td>\n",
       "      <td>4.927525</td>\n",
       "      <td>1.620165</td>\n",
       "      <td>MaxAbsScaler(copy=True)</td>\n",
       "      <td>{'scaler': MaxAbsScaler(copy=True)}</td>\n",
       "      <td>0.579264</td>\n",
       "      <td>0.564383</td>\n",
       "      <td>0.583122</td>\n",
       "      <td>0.587274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.579532</td>\n",
       "      <td>0.007989</td>\n",
       "      <td>4</td>\n",
       "      <td>0.596891</td>\n",
       "      <td>0.579196</td>\n",
       "      <td>0.590372</td>\n",
       "      <td>0.594132</td>\n",
       "      <td>0.597304</td>\n",
       "      <td>0.591579</td>\n",
       "      <td>0.006668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.987427</td>\n",
       "      <td>0.311313</td>\n",
       "      <td>2.965020</td>\n",
       "      <td>0.534475</td>\n",
       "      <td>RobustScaler(copy=True, quantile_range=(25.0, ...</td>\n",
       "      <td>{'scaler': RobustScaler(copy=True, quantile_ra...</td>\n",
       "      <td>0.575935</td>\n",
       "      <td>0.562004</td>\n",
       "      <td>0.588515</td>\n",
       "      <td>0.582037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578104</td>\n",
       "      <td>0.008981</td>\n",
       "      <td>5</td>\n",
       "      <td>0.595661</td>\n",
       "      <td>0.577015</td>\n",
       "      <td>0.593901</td>\n",
       "      <td>0.586717</td>\n",
       "      <td>0.594568</td>\n",
       "      <td>0.589572</td>\n",
       "      <td>0.007023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       3.325717      1.584996         5.858148        1.601921   \n",
       "1       3.307196      1.115818         3.752201        0.997321   \n",
       "2       4.755791      1.219479         3.382347        1.178871   \n",
       "3       4.119946      1.098841         4.927525        1.620165   \n",
       "4       2.987427      0.311313         2.965020        0.534475   \n",
       "\n",
       "                                        param_scaler  \\\n",
       "0  StandardScaler(copy=True, with_mean=True, with...   \n",
       "1                   Normalizer(copy=True, norm='l2')   \n",
       "2      MinMaxScaler(copy=True, feature_range=(0, 1))   \n",
       "3                            MaxAbsScaler(copy=True)   \n",
       "4  RobustScaler(copy=True, quantile_range=(25.0, ...   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'scaler': StandardScaler(copy=True, with_mean...           0.571972   \n",
       "1       {'scaler': Normalizer(copy=True, norm='l2')}           0.576094   \n",
       "2  {'scaler': MinMaxScaler(copy=True, feature_ran...           0.579264   \n",
       "3                {'scaler': MaxAbsScaler(copy=True)}           0.579264   \n",
       "4  {'scaler': RobustScaler(copy=True, quantile_ra...           0.575935   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score       ...         \\\n",
       "0           0.584681           0.585660           0.586322       ...          \n",
       "1           0.583095           0.587722           0.588385       ...          \n",
       "2           0.564859           0.583439           0.587591       ...          \n",
       "3           0.564383           0.583122           0.587274       ...          \n",
       "4           0.562004           0.588515           0.582037       ...          \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0         0.582419        0.005313                2            0.593440   \n",
       "1         0.583624        0.004407                1            0.594670   \n",
       "2         0.579754        0.007901                3            0.597010   \n",
       "3         0.579532        0.007989                4            0.596891   \n",
       "4         0.578104        0.008981                5            0.595661   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0            0.595733            0.593941            0.594409   \n",
       "1            0.596129            0.594734            0.592149   \n",
       "2            0.579434            0.591244            0.594251   \n",
       "3            0.579196            0.590372            0.594132   \n",
       "4            0.577015            0.593901            0.586717   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.595757          0.594656         0.000941  \n",
       "1            0.594568          0.594450         0.001285  \n",
       "2            0.597145          0.591817         0.006557  \n",
       "3            0.597304          0.591579         0.006668  \n",
       "4            0.594568          0.589572         0.007023  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_kn.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K value testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_dict = new_unique_df[your_features2].to_dict(orient=\"records\")\n",
    "y_train = new_unique_df['outcome_type']\n",
    "\n",
    "vec = DictVectorizer(sparse=False)\n",
    "vec.fit(x_train_dict)\n",
    "x_train = vec.transform(x_train_dict)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_sc = scaler.transform(x_train)\n",
    "\n",
    "model = KNeighborsClassifier(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = [5,10,20,30,40,50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [5, 10, 20, 30, 40, 50]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_kn_k = GridSearchCV(model,param_grid=dict(n_neighbors=ks),cv=5)\n",
    "grid_kn_k.fit(x_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5852103292938265\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "print(grid_kn_k.best_score_)\n",
    "print(grid_kn_k.best_estimator_.n_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22c83162e10>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(grid_kn_k.cv_results_).set_index(\"param_n_neighbors\")['mean_test_score'].plot.line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy = 0.5852103292938265\n",
    "\n",
    "k = 50\n",
    "\n",
    "scaler = RobustScaler()\n",
    "\n",
    "features = your_features1\n",
    "\n",
    "model = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
    "           weights='uniform'),\n",
    "       fit_params=None, iid='warn', n_jobs=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['is_mixed', 'intake_condition', 'intake_type', 'sex', 'fixed', 'age_in', 'has_name'] 0.5573572834417051\n",
      "['intake_condition', 'intake_type', 'sex', 'fixed', 'age_in', 'has_name'] 0.560117919123176\n",
      "['is_mixed', 'intake_type', 'sex', 'fixed', 'age_in', 'has_name'] 0.5576118252178109\n",
      "['is_mixed', 'sex', 'fixed', 'age_in', 'has_name'] 0.5051411440320803\n",
      "['intake_condition', 'sex', 'age_in', 'has_name'] 0.49016599989010273\n",
      "['is_mixed', 'sex', 'fixed', 'age_in'] 0.5033957571438188\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_jobs=-1)\n",
    "vec = DictVectorizer(sparse=False)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"vectorizer\", vec), \n",
    "    (\"scaler\", scaler), \n",
    "    (\"model\", model)\n",
    "])\n",
    "\n",
    "\n",
    "for feat in your_features:\n",
    "    x_train_dict = new_unique_df[feat].to_dict(orient=\"records\")\n",
    "    y_train = new_unique_df['outcome_type']\n",
    "    print(feat, cross_val_score(pipeline, x_train_dict, y_train, cv=5, scoring=\"accuracy\").mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaler Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_dict = new_unique_df[your_features2].to_dict(orient=\"records\")\n",
    "y_train = new_unique_df['outcome_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = [StandardScaler(), Normalizer(), MinMaxScaler(), MaxAbsScaler(), RobustScaler()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  25 | elapsed:    7.3s remaining:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  25 | elapsed:    7.7s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    8.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vectorizer', DictVectorizer(dtype=<class 'numpy.float64'>, separator='=', sort=True,\n",
       "        sparse=False)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('model', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None..._jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'scaler': [StandardScaler(copy=True, with_mean=True, with_std=True), Normalizer(copy=True, norm='l2'), MinMaxScaler(copy=True, feature_range=(0, 1)), MaxAbsScaler(copy=True), RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
       "       with_scaling=True)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=5)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rf = GridSearchCV(pipeline,param_grid=dict(scaler=scalers),cv=5, verbose=5, n_jobs=-1)\n",
    "grid_rf.fit(x_train_dict, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5603388109891504\n",
      "[('vectorizer', DictVectorizer(dtype=<class 'numpy.float64'>, separator='=', sort=True,\n",
      "        sparse=False)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('model', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False))]\n"
     ]
    }
   ],
   "source": [
    "print(grid_rf.best_score_)\n",
    "print(grid_rf.best_estimator_.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_scaler</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.369064</td>\n",
       "      <td>0.029137</td>\n",
       "      <td>0.152427</td>\n",
       "      <td>0.003708</td>\n",
       "      <td>StandardScaler(copy=True, with_mean=True, with...</td>\n",
       "      <td>{'scaler': StandardScaler(copy=True, with_mean...</td>\n",
       "      <td>0.555485</td>\n",
       "      <td>0.555186</td>\n",
       "      <td>0.563135</td>\n",
       "      <td>0.567122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560339</td>\n",
       "      <td>0.004564</td>\n",
       "      <td>1</td>\n",
       "      <td>0.678234</td>\n",
       "      <td>0.678498</td>\n",
       "      <td>0.676818</td>\n",
       "      <td>0.676170</td>\n",
       "      <td>0.678707</td>\n",
       "      <td>0.677685</td>\n",
       "      <td>0.001006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.503892</td>\n",
       "      <td>0.138838</td>\n",
       "      <td>0.201427</td>\n",
       "      <td>0.058907</td>\n",
       "      <td>Normalizer(copy=True, norm='l2')</td>\n",
       "      <td>{'scaler': Normalizer(copy=True, norm='l2')}</td>\n",
       "      <td>0.556119</td>\n",
       "      <td>0.553283</td>\n",
       "      <td>0.565831</td>\n",
       "      <td>0.562044</td>\n",
       "      <td>...</td>\n",
       "      <td>0.559451</td>\n",
       "      <td>0.004402</td>\n",
       "      <td>3</td>\n",
       "      <td>0.678234</td>\n",
       "      <td>0.680084</td>\n",
       "      <td>0.678880</td>\n",
       "      <td>0.677676</td>\n",
       "      <td>0.681364</td>\n",
       "      <td>0.679248</td>\n",
       "      <td>0.001327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.684687</td>\n",
       "      <td>0.065767</td>\n",
       "      <td>0.189344</td>\n",
       "      <td>0.017661</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>{'scaler': MinMaxScaler(copy=True, feature_ran...</td>\n",
       "      <td>0.554534</td>\n",
       "      <td>0.553758</td>\n",
       "      <td>0.564245</td>\n",
       "      <td>0.566011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.559387</td>\n",
       "      <td>0.004974</td>\n",
       "      <td>4</td>\n",
       "      <td>0.678512</td>\n",
       "      <td>0.679370</td>\n",
       "      <td>0.676541</td>\n",
       "      <td>0.675734</td>\n",
       "      <td>0.679302</td>\n",
       "      <td>0.677892</td>\n",
       "      <td>0.001486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.618886</td>\n",
       "      <td>0.051515</td>\n",
       "      <td>0.208576</td>\n",
       "      <td>0.021267</td>\n",
       "      <td>MaxAbsScaler(copy=True)</td>\n",
       "      <td>{'scaler': MaxAbsScaler(copy=True)}</td>\n",
       "      <td>0.556278</td>\n",
       "      <td>0.557723</td>\n",
       "      <td>0.563610</td>\n",
       "      <td>0.565376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560022</td>\n",
       "      <td>0.003721</td>\n",
       "      <td>2</td>\n",
       "      <td>0.678036</td>\n",
       "      <td>0.678656</td>\n",
       "      <td>0.676501</td>\n",
       "      <td>0.675535</td>\n",
       "      <td>0.678628</td>\n",
       "      <td>0.677471</td>\n",
       "      <td>0.001245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.566277</td>\n",
       "      <td>0.129148</td>\n",
       "      <td>0.156887</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>RobustScaler(copy=True, quantile_range=(25.0, ...</td>\n",
       "      <td>{'scaler': RobustScaler(copy=True, quantile_ra...</td>\n",
       "      <td>0.550729</td>\n",
       "      <td>0.554710</td>\n",
       "      <td>0.563135</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.557960</td>\n",
       "      <td>0.005405</td>\n",
       "      <td>5</td>\n",
       "      <td>0.678115</td>\n",
       "      <td>0.678299</td>\n",
       "      <td>0.677096</td>\n",
       "      <td>0.676209</td>\n",
       "      <td>0.678906</td>\n",
       "      <td>0.677725</td>\n",
       "      <td>0.000956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.369064      0.029137         0.152427        0.003708   \n",
       "1       0.503892      0.138838         0.201427        0.058907   \n",
       "2       0.684687      0.065767         0.189344        0.017661   \n",
       "3       0.618886      0.051515         0.208576        0.021267   \n",
       "4       0.566277      0.129148         0.156887        0.013699   \n",
       "\n",
       "                                        param_scaler  \\\n",
       "0  StandardScaler(copy=True, with_mean=True, with...   \n",
       "1                   Normalizer(copy=True, norm='l2')   \n",
       "2      MinMaxScaler(copy=True, feature_range=(0, 1))   \n",
       "3                            MaxAbsScaler(copy=True)   \n",
       "4  RobustScaler(copy=True, quantile_range=(25.0, ...   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'scaler': StandardScaler(copy=True, with_mean...           0.555485   \n",
       "1       {'scaler': Normalizer(copy=True, norm='l2')}           0.556119   \n",
       "2  {'scaler': MinMaxScaler(copy=True, feature_ran...           0.554534   \n",
       "3                {'scaler': MaxAbsScaler(copy=True)}           0.556278   \n",
       "4  {'scaler': RobustScaler(copy=True, quantile_ra...           0.550729   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score       ...         \\\n",
       "0           0.555186           0.563135           0.567122       ...          \n",
       "1           0.553283           0.565831           0.562044       ...          \n",
       "2           0.553758           0.564245           0.566011       ...          \n",
       "3           0.557723           0.563610           0.565376       ...          \n",
       "4           0.554710           0.563135           0.565217       ...          \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0         0.560339        0.004564                1            0.678234   \n",
       "1         0.559451        0.004402                3            0.678234   \n",
       "2         0.559387        0.004974                4            0.678512   \n",
       "3         0.560022        0.003721                2            0.678036   \n",
       "4         0.557960        0.005405                5            0.678115   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0            0.678498            0.676818            0.676170   \n",
       "1            0.680084            0.678880            0.677676   \n",
       "2            0.679370            0.676541            0.675734   \n",
       "3            0.678656            0.676501            0.675535   \n",
       "4            0.678299            0.677096            0.676209   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.678707          0.677685         0.001006  \n",
       "1            0.681364          0.679248         0.001327  \n",
       "2            0.679302          0.677892         0.001486  \n",
       "3            0.678628          0.677471         0.001245  \n",
       "4            0.678906          0.677725         0.000956  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_rf.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_dict = new_unique_df[your_features2].to_dict(orient=\"records\")\n",
    "y_train = new_unique_df['outcome_type']\n",
    "\n",
    "vec = DictVectorizer(sparse=False)\n",
    "vec.fit(x_train_dict)\n",
    "x_train = vec.transform(x_train_dict)\n",
    "\n",
    "scaler = Normalizer()\n",
    "scaler.fit(x_train)\n",
    "x_train_sc = scaler.transform(x_train)\n",
    "\n",
    "model = RandomForestClassifier(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [10, 50, 90, 100],\n",
    "    'max_features': [2, 3],\n",
    "    'random_state': [10],\n",
    "    'min_samples_leaf': [2, 3, 4],\n",
    "    'min_samples_split': [10, 12, 15],\n",
    "    'n_estimators': [300, 1000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   52.7s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed: 16.0min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed: 30.1min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed: 35.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'bootstrap': [True], 'max_depth': [10, 50, 90, 100], 'max_features': [2, 3], 'random_state': [10], 'min_samples_leaf': [2, 3, 4], 'min_samples_split': [10, 12, 15], 'n_estimators': [300, 1000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=2)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rf_p = GridSearchCV(model,param_grid=param_grid,cv=5, n_jobs=-1, verbose=2)\n",
    "grid_rf_p.fit(x_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5921895818793224\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=10, max_features=3, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=2, min_samples_split=15,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,\n",
      "            oob_score=False, random_state=10, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(grid_rf_p.best_score_)\n",
    "print(grid_rf_p.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy = 0.5921895818793224\n",
    "\n",
    "scaler = Normalizer()\n",
    "\n",
    "features = your_features2\n",
    "\n",
    "model = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=90, max_features=2, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=2, min_samples_split=15,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,\n",
    "            oob_score=False, random_state=10, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]['is_mixed', 'intake_condition', 'intake_type', 'sex', 'fixed', 'age_in', 'has_name'] 0.5825460621524394\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]['intake_condition', 'intake_type', 'sex', 'fixed', 'age_in', 'has_name'] 0.5815626097334865\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]['is_mixed', 'intake_type', 'sex', 'fixed', 'age_in', 'has_name'] 0.5793419885715285\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]['is_mixed', 'sex', 'fixed', 'age_in', 'has_name'] 0.5220492634024069\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]['intake_condition', 'sex', 'age_in', 'has_name'] 0.5005709552426022\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]['is_mixed', 'sex', 'fixed', 'age_in'] 0.5220492634024069\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC(verbose=2)\n",
    "vec = DictVectorizer(sparse=False)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"vectorizer\", vec), \n",
    "    (\"scaler\", scaler), \n",
    "    (\"model\", model)\n",
    "])\n",
    "\n",
    "\n",
    "for feat in your_features:\n",
    "    x_train_dict = new_unique_df[feat].to_dict(orient=\"records\")\n",
    "    y_train = new_unique_df['outcome_type']\n",
    "    print(feat, cross_val_score(pipeline, x_train_dict, y_train, cv=5, scoring=\"accuracy\").mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaler Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_dict = new_unique_df[your_features2].to_dict(orient=\"records\")\n",
    "y_train = new_unique_df['outcome_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = [StandardScaler(), Normalizer(), MinMaxScaler(), MaxAbsScaler(), RobustScaler()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  25 | elapsed:   59.8s remaining:   33.6s\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  25 | elapsed:  1.2min remaining:    9.6s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vectorizer', DictVectorizer(dtype=<class 'numpy.float64'>, separator='=', sort=True,\n",
       "        sparse=False)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('model', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=2))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'scaler': [StandardScaler(copy=True, with_mean=True, with_std=True), Normalizer(copy=True, norm='l2'), MinMaxScaler(copy=True, feature_range=(0, 1)), MaxAbsScaler(copy=True), RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
       "       with_scaling=True)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=5)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_ls = GridSearchCV(pipeline,param_grid=dict(scaler=scalers),cv=5, verbose=5, n_jobs=-1)\n",
    "grid_ls.fit(x_train_dict, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5817207030010786\n",
      "[('vectorizer', DictVectorizer(dtype=<class 'numpy.float64'>, separator='=', sort=True,\n",
      "        sparse=False)), ('scaler', RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "       with_scaling=True)), ('model', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=2))]\n"
     ]
    }
   ],
   "source": [
    "print(grid_ls.best_score_)\n",
    "print(grid_ls.best_estimator_.steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_dict = new_unique_df[your_features2].to_dict(orient=\"records\")\n",
    "y_train = new_unique_df['outcome_type']\n",
    "\n",
    "vec = DictVectorizer(sparse=False)\n",
    "vec.fit(x_train_dict)\n",
    "x_train = vec.transform(x_train_dict)\n",
    "\n",
    "scaler = Normalizer()\n",
    "scaler.fit(x_train)\n",
    "x_train_sc = scaler.transform(x_train)\n",
    "\n",
    "model = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "    'max_iter': [500,1000,1500]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done  75 out of  75 | elapsed:   56.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10], 'max_iter': [500, 1000, 1500]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=2)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_ls_p = GridSearchCV(model,param_grid=param_grid,cv=5, n_jobs=-1, verbose=2)\n",
    "grid_ls_p.fit(x_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.568333227587082\n",
      "LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=500,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n"
     ]
    }
   ],
   "source": [
    "print(grid_ls_p.best_score_)\n",
    "print(grid_ls_p.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy = 0.568333227587082\n",
    "\n",
    "scaler = Normalizer()\n",
    "\n",
    "features = features\n",
    "\n",
    "model = LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
    "     intercept_scaling=1, loss='squared_hinge', max_iter=500,\n",
    "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
    "     verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['is_mixed', 'intake_condition', 'intake_type', 'sex', 'fixed', 'age_in', 'has_name'] 0.5586577834647615\n",
      "['intake_condition', 'intake_type', 'sex', 'fixed', 'age_in', 'has_name'] 0.5605622126610765\n",
      "['is_mixed', 'intake_type', 'sex', 'fixed', 'age_in', 'has_name'] 0.5592935488012417\n",
      "['is_mixed', 'sex', 'fixed', 'age_in', 'has_name'] 0.5045376377427448\n",
      "['intake_condition', 'sex', 'age_in', 'has_name'] 0.4891822055630194\n",
      "['is_mixed', 'sex', 'fixed', 'age_in'] 0.5042838003603564\n"
     ]
    }
   ],
   "source": [
    "model = BaggingClassifier(n_jobs=-1)\n",
    "vec = DictVectorizer(sparse=False)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"vectorizer\", vec), \n",
    "    (\"scaler\", scaler), \n",
    "    (\"model\", model)\n",
    "])\n",
    "\n",
    "\n",
    "for feat in your_features:\n",
    "    x_train_dict = new_unique_df[feat].to_dict(orient=\"records\")\n",
    "    y_train = new_unique_df['outcome_type']\n",
    "    print(feat, cross_val_score(pipeline, x_train_dict, y_train, cv=5, scoring=\"accuracy\").mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaler Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_dict = new_unique_df[your_features1].to_dict(orient=\"records\")\n",
    "y_train = new_unique_df['outcome_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = [StandardScaler(), Normalizer(), MinMaxScaler(), MaxAbsScaler(), RobustScaler()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  25 | elapsed:    8.6s remaining:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  25 | elapsed:    9.8s remaining:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:   10.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vectorizer', DictVectorizer(dtype=<class 'numpy.float64'>, separator='=', sort=True,\n",
       "        sparse=False)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('model', BaggingClassifier(base_estimator=None, bootstrap=True,\n",
       "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
       "         n_estimators=10, n_jobs=-1, oob_score=False, random_state=None,\n",
       "         verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'scaler': [StandardScaler(copy=True, with_mean=True, with_std=True), Normalizer(copy=True, norm='l2'), MinMaxScaler(copy=True, feature_range=(0, 1)), MaxAbsScaler(copy=True), RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
       "       with_scaling=True)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=5)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_bc = GridSearchCV(pipeline,param_grid=dict(scaler=scalers),cv=5, verbose=5, n_jobs=-1)\n",
    "grid_bc.fit(x_train_dict, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.560370534864539\n",
      "[('vectorizer', DictVectorizer(dtype=<class 'numpy.float64'>, separator='=', sort=True,\n",
      "        sparse=False)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('model', BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=10, n_jobs=-1, oob_score=False, random_state=None,\n",
      "         verbose=0, warm_start=False))]\n"
     ]
    }
   ],
   "source": [
    "print(grid_bc.best_score_)\n",
    "print(grid_bc.best_estimator_.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_scaler</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.693277</td>\n",
       "      <td>0.063658</td>\n",
       "      <td>0.070887</td>\n",
       "      <td>0.003383</td>\n",
       "      <td>StandardScaler(copy=True, with_mean=True, with...</td>\n",
       "      <td>{'scaler': StandardScaler(copy=True, with_mean...</td>\n",
       "      <td>0.556595</td>\n",
       "      <td>0.555820</td>\n",
       "      <td>0.565990</td>\n",
       "      <td>0.568232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560371</td>\n",
       "      <td>0.005565</td>\n",
       "      <td>1</td>\n",
       "      <td>0.688863</td>\n",
       "      <td>0.688095</td>\n",
       "      <td>0.686970</td>\n",
       "      <td>0.686043</td>\n",
       "      <td>0.687946</td>\n",
       "      <td>0.687583</td>\n",
       "      <td>0.000978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.703493</td>\n",
       "      <td>0.340098</td>\n",
       "      <td>0.123836</td>\n",
       "      <td>0.022457</td>\n",
       "      <td>Normalizer(copy=True, norm='l2')</td>\n",
       "      <td>{'scaler': Normalizer(copy=True, norm='l2')}</td>\n",
       "      <td>0.554217</td>\n",
       "      <td>0.555344</td>\n",
       "      <td>0.563610</td>\n",
       "      <td>0.559346</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558150</td>\n",
       "      <td>0.003305</td>\n",
       "      <td>5</td>\n",
       "      <td>0.688030</td>\n",
       "      <td>0.687976</td>\n",
       "      <td>0.686533</td>\n",
       "      <td>0.684933</td>\n",
       "      <td>0.686875</td>\n",
       "      <td>0.686870</td>\n",
       "      <td>0.001135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.984493</td>\n",
       "      <td>0.057858</td>\n",
       "      <td>0.131823</td>\n",
       "      <td>0.026012</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>{'scaler': MinMaxScaler(copy=True, feature_ran...</td>\n",
       "      <td>0.551363</td>\n",
       "      <td>0.557564</td>\n",
       "      <td>0.565514</td>\n",
       "      <td>0.562361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558467</td>\n",
       "      <td>0.004994</td>\n",
       "      <td>4</td>\n",
       "      <td>0.689220</td>\n",
       "      <td>0.688174</td>\n",
       "      <td>0.687604</td>\n",
       "      <td>0.684655</td>\n",
       "      <td>0.689413</td>\n",
       "      <td>0.687813</td>\n",
       "      <td>0.001714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.146454</td>\n",
       "      <td>0.089750</td>\n",
       "      <td>0.138183</td>\n",
       "      <td>0.008665</td>\n",
       "      <td>MaxAbsScaler(copy=True)</td>\n",
       "      <td>{'scaler': MaxAbsScaler(copy=True)}</td>\n",
       "      <td>0.552156</td>\n",
       "      <td>0.558516</td>\n",
       "      <td>0.567735</td>\n",
       "      <td>0.567598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560339</td>\n",
       "      <td>0.006312</td>\n",
       "      <td>2</td>\n",
       "      <td>0.688863</td>\n",
       "      <td>0.687897</td>\n",
       "      <td>0.686692</td>\n",
       "      <td>0.685289</td>\n",
       "      <td>0.688660</td>\n",
       "      <td>0.687480</td>\n",
       "      <td>0.001334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.129060</td>\n",
       "      <td>0.089202</td>\n",
       "      <td>0.115846</td>\n",
       "      <td>0.016759</td>\n",
       "      <td>RobustScaler(copy=True, quantile_range=(25.0, ...</td>\n",
       "      <td>{'scaler': RobustScaler(copy=True, quantile_ra...</td>\n",
       "      <td>0.551522</td>\n",
       "      <td>0.556930</td>\n",
       "      <td>0.564404</td>\n",
       "      <td>0.562520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558594</td>\n",
       "      <td>0.004538</td>\n",
       "      <td>3</td>\n",
       "      <td>0.687951</td>\n",
       "      <td>0.687936</td>\n",
       "      <td>0.686573</td>\n",
       "      <td>0.686241</td>\n",
       "      <td>0.688779</td>\n",
       "      <td>0.687496</td>\n",
       "      <td>0.000946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.693277      0.063658         0.070887        0.003383   \n",
       "1       1.703493      0.340098         0.123836        0.022457   \n",
       "2       0.984493      0.057858         0.131823        0.026012   \n",
       "3       1.146454      0.089750         0.138183        0.008665   \n",
       "4       1.129060      0.089202         0.115846        0.016759   \n",
       "\n",
       "                                        param_scaler  \\\n",
       "0  StandardScaler(copy=True, with_mean=True, with...   \n",
       "1                   Normalizer(copy=True, norm='l2')   \n",
       "2      MinMaxScaler(copy=True, feature_range=(0, 1))   \n",
       "3                            MaxAbsScaler(copy=True)   \n",
       "4  RobustScaler(copy=True, quantile_range=(25.0, ...   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'scaler': StandardScaler(copy=True, with_mean...           0.556595   \n",
       "1       {'scaler': Normalizer(copy=True, norm='l2')}           0.554217   \n",
       "2  {'scaler': MinMaxScaler(copy=True, feature_ran...           0.551363   \n",
       "3                {'scaler': MaxAbsScaler(copy=True)}           0.552156   \n",
       "4  {'scaler': RobustScaler(copy=True, quantile_ra...           0.551522   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score       ...         \\\n",
       "0           0.555820           0.565990           0.568232       ...          \n",
       "1           0.555344           0.563610           0.559346       ...          \n",
       "2           0.557564           0.565514           0.562361       ...          \n",
       "3           0.558516           0.567735           0.567598       ...          \n",
       "4           0.556930           0.564404           0.562520       ...          \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0         0.560371        0.005565                1            0.688863   \n",
       "1         0.558150        0.003305                5            0.688030   \n",
       "2         0.558467        0.004994                4            0.689220   \n",
       "3         0.560339        0.006312                2            0.688863   \n",
       "4         0.558594        0.004538                3            0.687951   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0            0.688095            0.686970            0.686043   \n",
       "1            0.687976            0.686533            0.684933   \n",
       "2            0.688174            0.687604            0.684655   \n",
       "3            0.687897            0.686692            0.685289   \n",
       "4            0.687936            0.686573            0.686241   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.687946          0.687583         0.000978  \n",
       "1            0.686875          0.686870         0.001135  \n",
       "2            0.689413          0.687813         0.001714  \n",
       "3            0.688660          0.687480         0.001334  \n",
       "4            0.688779          0.687496         0.000946  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_bc.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_dict = new_unique_df[your_features1].to_dict(orient=\"records\")\n",
    "y_train = new_unique_df['outcome_type']\n",
    "\n",
    "vec = DictVectorizer(sparse=False)\n",
    "vec.fit(x_train_dict)\n",
    "x_train = vec.transform(x_train_dict)\n",
    "\n",
    "scaler = Normalizer()\n",
    "scaler.fit(x_train)\n",
    "x_train_sc = scaler.transform(x_train)\n",
    "\n",
    "model = BaggingClassifier(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_samples': [600,800,1000],\n",
    "    'max_features': [0.5, 0.75, 1],\n",
    "    'random_state': [10],\n",
    "    'n_estimators': [100, 200, 300, 500]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=BaggingClassifier(base_estimator=None, bootstrap=True,\n",
       "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
       "         n_estimators=10, n_jobs=-1, oob_score=False, random_state=None,\n",
       "         verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_samples': [600, 800, 1000], 'max_features': [0.5, 0.75, 1], 'random_state': [10], 'n_estimators': [100, 200, 300, 500]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=2)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_bc_p = GridSearchCV(model,param_grid=param_grid,cv=5, n_jobs=-1, verbose=2)\n",
    "grid_bc_p.fit(x_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5895565002220672\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=0.75, max_samples=800,\n",
      "         n_estimators=500, n_jobs=-1, oob_score=False, random_state=10,\n",
      "         verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(grid_bc_p.best_score_)\n",
    "print(grid_bc_p.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy = 0.5895565002220672\n",
    "\n",
    "scaler = Normalizer()\n",
    "\n",
    "features = features\n",
    "\n",
    "model = BaggingClassifier(base_estimator=None, bootstrap=True,\n",
    "         bootstrap_features=False, max_features=0.75, max_samples=800,\n",
    "         n_estimators=500, n_jobs=-1, oob_score=False, random_state=10,\n",
    "         verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting what will happen to your dog\n",
    "* **Best Model: RandomForestClassifier**\n",
    "\n",
    "* 2nd Best Model: BaggingClassifier\n",
    "* 3rd Model: KNeighborsClassifier\n",
    "* Worst Model: LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features=3, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=2, min_samples_split=15,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,\n",
       "            oob_score=False, random_state=10, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_dict = new_unique_df[your_features2].to_dict(orient=\"records\")\n",
    "y_train = new_unique_df['outcome_type']\n",
    "\n",
    "vec = DictVectorizer(sparse=False)\n",
    "vec.fit(x_train_dict)\n",
    "x_train = vec.transform(x_train_dict)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_sc = scaler.transform(x_train)\n",
    "\n",
    "model = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=10, max_features=3, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=2, min_samples_split=15,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,\n",
    "            oob_score=False, random_state=10, verbose=0, warm_start=False)\n",
    "\n",
    "model.fit(x_train_sc, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing our best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting outcome of Dog 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Euthanasia'], dtype=object)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dog = pd.DataFrame()\n",
    "new_dog['intake_condition'] = ['Sick']\n",
    "new_dog['intake_type'] = ['Owner Surrender']\n",
    "new_dog['sex'] = ['Male']\n",
    "new_dog['fixed'] = [\"Yes\"]\n",
    "new_dog['age_in'] = [15]\n",
    "new_dog['has_name'] = [1]\n",
    "\n",
    "new_dog = new_dog.to_dict(orient=\"records\")\n",
    "new_dog = vec.transform(new_dog)\n",
    "new_dog_sc = scaler.transform(new_dog)\n",
    "\n",
    "model.predict(new_dog_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting outcome of Dog 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Adoption'], dtype=object)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dog_2 = pd.DataFrame()\n",
    "new_dog_2['intake_condition'] = ['Normal']\n",
    "new_dog_2['intake_type'] = ['Stray']\n",
    "new_dog_2['sex'] = ['Female']\n",
    "new_dog_2['fixed'] = [\"No\"]\n",
    "new_dog_2['age_in'] = [2]\n",
    "new_dog_2['has_name'] = [0]\n",
    "\n",
    "new_dog_2 = new_dog_2.to_dict(orient=\"records\")\n",
    "new_dog_2 = vec.transform(new_dog_2)\n",
    "new_dog_2_sc = scaler.transform(new_dog_2)\n",
    "\n",
    "model.predict(new_dog_2_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting outcome of Dog 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Transfer'], dtype=object)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dog_3 = pd.DataFrame()\n",
    "new_dog_3['intake_condition'] = ['Feral']\n",
    "new_dog_3['intake_type'] = ['Stray']\n",
    "new_dog_3['sex'] = ['Male']\n",
    "new_dog_3['fixed'] = [\"No\"]\n",
    "new_dog_3['age_in'] = [4]\n",
    "new_dog_3['has_name'] = [0]\n",
    "\n",
    "new_dog_3 = new_dog_3.to_dict(orient=\"records\")\n",
    "new_dog_3 = vec.transform(new_dog_3)\n",
    "new_dog_3_sc = scaler.transform(new_dog_3)\n",
    "\n",
    "model.predict(new_dog_3_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "**Dog 1:** A sick, male, neutured dog that was surrendered by it's owner at 15 years old was predicted to be euthanized.\n",
    "\n",
    "**Dog 2:** A normal, female, unspayed, 2 year old, unnamed, stray dog was predicted to be Adopted. :)\n",
    "\n",
    "**Dog 3:** A feral, male, unneutered, 4 year old, unnamed dog was predicted to be Transfered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
